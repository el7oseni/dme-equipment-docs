"""
DME EQUIPMENT DOCUMENTATION WEB APP
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
Complete web interface for processing DME equipment photos

Features:
‚úÖ Upload multiple photos (or ZIP file)
‚úÖ Automatic batch processing (50 docs per folder)
‚úÖ Real-time progress tracking
‚úÖ Organized Google Drive folders
‚úÖ CSV export with all results
‚úÖ Beautiful, simple UI

Deploy: streamlit run dme_webapp.py
"""

import streamlit as st
import os
import json
import time
import zipfile
import io
from datetime import datetime
from pathlib import Path
import pandas as pd

import google.generativeai as genai
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from google_auth_oauthlib.flow import InstalledAppFlow
from googleapiclient.discovery import build
from PIL import Image

# ============================================================================
# CONFIGURATION
# ============================================================================

GEMINI_API_KEY = st.secrets.get("GEMINI_API_KEY", "AIzaSyBdz2FTycDrxoWSmZGXYcp77qSETNmKuBg")
OAUTH_CREDENTIALS_FILE = "oauth_credentials.json"
TOKEN_FILE = "token.json"
BASE_FOLDER_ID = st.secrets.get("FOLDER_ID", "1exL34puBaxIj1DkBpykEgWzEOf9CdBXl")

SCOPES = [
    'https://www.googleapis.com/auth/documents',
    'https://www.googleapis.com/auth/drive'
]

BATCH_SIZE = 50  # Documents per operation folder

# ============================================================================
# PAGE CONFIG
# ============================================================================

st.set_page_config(
    page_title="DME Pro - Equipment Documentation",
    page_icon="üìÑ",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Custom CSS
st.markdown("""
<style>
    .main-header {
        text-align: center;
        padding: 2rem 0;
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        color: white;
        border-radius: 10px;
        margin-bottom: 2rem;
    }
    .success-box {
        padding: 1rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .error-box {
        padding: 1rem;
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        margin: 1rem 0;
    }
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# AUTHENTICATION
# ============================================================================

@st.cache_resource
def get_credentials():
    """Get Google OAuth credentials"""
    creds = None
    if os.path.exists(TOKEN_FILE):
        creds = Credentials.from_authorized_user_file(TOKEN_FILE, SCOPES)
    if not creds or not creds.valid:
        if creds and creds.expired and creds.refresh_token:
            creds.refresh(Request())
        else:
            if os.path.exists(OAUTH_CREDENTIALS_FILE):
                flow = InstalledAppFlow.from_client_secrets_file(
                    OAUTH_CREDENTIALS_FILE, SCOPES)
                creds = flow.run_local_server(port=0)
            else:
                st.error("‚ùå oauth_credentials.json not found!")
                st.stop()
        with open(TOKEN_FILE, 'w') as token:
            token.write(creds.to_json())
    return creds

@st.cache_resource
def get_services():
    """Initialize Google API services"""
    creds = get_credentials()
    docs_service = build('docs', 'v1', credentials=creds)
    drive_service = build('drive', 'v3', credentials=creds)
    return docs_service, drive_service

# ============================================================================
# GOOGLE DRIVE FUNCTIONS
# ============================================================================

def create_drive_folder(folder_name, parent_id=None):
    """Create folder in Google Drive"""
    _, drive_service = get_services()
    
    file_metadata = {
        'name': folder_name,
        'mimeType': 'application/vnd.google-apps.folder'
    }
    
    if parent_id:
        file_metadata['parents'] = [parent_id]
    
    folder = drive_service.files().create(
        body=file_metadata,
        fields='id'
    ).execute()
    
    return folder.get('id')

def upload_csv_to_drive(csv_data, filename, folder_id):
    """Upload CSV to Google Drive"""
    _, drive_service = get_services()
    
    file_metadata = {
        'name': filename,
        'mimeType': 'text/csv',
        'parents': [folder_id]
    }
    
    media = io.BytesIO(csv_data.encode('utf-8'))
    
    from googleapiclient.http import MediaIoBaseUpload
    
    file = drive_service.files().create(
        body=file_metadata,
        media_body=MediaIoBaseUpload(media, mimetype='text/csv'),
        fields='id'
    ).execute()
    
    return file.get('id')

# ============================================================================
# DATA EXTRACTION
# ============================================================================

def extract_equipment_data(image_bytes):
    """Extract equipment data using Gemini"""
    
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
    
    img = Image.open(io.BytesIO(image_bytes))
    
    prompt = """
You are analyzing a DME (Durable Medical Equipment) label photo.

Extract these fields with HIGH ACCURACY:

1. Device/Equipment Type: What is this equipment?
2. Model Number: The model/reference number
3. Serial Number: The unique serial number (CAREFUL: A‚â†4, O‚â†0, I‚â†1, S‚â†5)
4. Manufacturer: Company name (if visible)

Return ONLY valid JSON:
{
  "device": "equipment type",
  "model": "model number",
  "serial": "serial number",
  "manufacturer": "manufacturer or n/a"
}
"""
    
    response = model.generate_content([prompt, img])
    text = response.text.strip()
    
    if '```json' in text:
        text = text.split('```json')[1].split('```')[0].strip()
    elif '```' in text:
        text = text.split('```')[1].split('```')[0].strip()
    
    data = json.loads(text)
    return data

# ============================================================================
# DOCUMENT CREATION
# ============================================================================

def create_equipment_doc(data, folder_id):
    """Create perfect Google Doc"""
    
    docs_service, drive_service = get_services()
    
    # Create document
    doc_title = f"{data['device']} - {data['serial']}"
    
    file_metadata = {
        'name': doc_title,
        'mimeType': 'application/vnd.google-apps.document',
        'parents': [folder_id]
    }
    
    file = drive_service.files().create(body=file_metadata, fields='id').execute()
    doc_id = file.get('id')
    
    # Build content
    device_line = f"Device: {data['device']}"
    model_line = f"Model: {data['model']}"
    serial_line = f"Serial Number: {data['serial']}"
    manufacturer_line = f"Manufacturer: {data['manufacturer']}"
    
    device_spaces = " " * max(3, 45 - len(device_line))
    serial_spaces = " " * max(3, 40 - len(serial_line))
    
    content = f"""Section 7 Equipment Management

DME PRO
126 W. Beech ST. Fallbrook CA 92028
PH:(760)879-1071 Fax:(760)437-5254

EQUIPMENT HISTORY RECORD

{device_line}{device_spaces}{model_line}

{serial_line}{serial_spaces}{manufacturer_line}

"""
    
    # Insert content
    requests = [{'insertText': {'location': {'index': 1}, 'text': content}}]
    docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()
    
    # Add table
    doc = docs_service.documents().get(documentId=doc_id).execute()
    end_index = doc['body']['content'][-1]['endIndex'] - 1
    
    requests = [{'insertTable': {'location': {'index': end_index}, 'rows': 9, 'columns': 8}}]
    docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()
    
    # Add table headers
    doc = docs_service.documents().get(documentId=doc_id).execute()
    table_start_index = None
    
    for element in doc['body']['content']:
        if 'table' in element:
            table_start_index = element['startIndex']
            table = element['table']
            first_row = table['tableRows'][0]
            
            table_headers = [
                "Date &\nInit's", "Clean", "Inspection", "Preventive\nMaintenance",
                "Repair\nHaz/Recall", "Return to Stock (S)or Mfr.\n(M)",
                "Patient/Facility\nName", "Pick-up\nDate"
            ]
            
            requests = []
            for i in range(len(first_row['tableCells']) - 1, -1, -1):
                if i < len(table_headers):
                    cell = first_row['tableCells'][i]
                    cell_idx = cell['content'][0]['startIndex']
                    requests.append({
                        'insertText': {'location': {'index': cell_idx}, 'text': table_headers[i]}
                    })
            
            docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()
            break
    
    # Gray header removed (API compatibility issue)
    # Documents work perfectly without it
    if table_start_index:
        print("       ‚úì Table header ready (no gray background)")
    
    # Column widths
    if table_start_index:
        column_widths = [60, 40, 50, 80, 60, 80, 70, 48]
        width_requests = []
        for col_idx, width in enumerate(column_widths):
            width_requests.append({
                'updateTableColumnProperties': {
                    'tableStartLocation': {'index': table_start_index},
                    'columnIndices': [col_idx],
                    'tableColumnProperties': {
                        'widthType': 'FIXED_WIDTH',
                        'width': {'magnitude': width, 'unit': 'PT'}
                    },
                    'fields': 'width,widthType'
                }
            })
        
        try:
            docs_service.documents().batchUpdate(
                documentId=doc_id, body={'requests': width_requests}
            ).execute()
        except: pass
    
    # Footer
    doc = docs_service.documents().get(documentId=doc_id).execute()
    end_index = doc['body']['content'][-1]['endIndex'] - 1
    
    requests = [{
        'insertText': {
            'location': {'index': end_index},
            'text': '\n\nCopyright¬© 1997-2009 The Compliance Team, Inc. ALL RIGHTS RESERVED'
        }
    }]
    docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': requests}).execute()
    
    # Formatting
    doc = docs_service.documents().get(documentId=doc_id).execute()
    all_text = ""
    for element in doc['body']['content']:
        if 'paragraph' in element:
            for elem in element['paragraph']['elements']:
                if 'textRun' in elem:
                    all_text += elem['textRun']['content']
    
    pos_dme = all_text.find("DME PRO") + 1
    pos_address = all_text.find("126 W.") + 1
    pos_phone = all_text.find("PH:(760)") + 1
    pos_title = all_text.find("EQUIPMENT HISTORY") + 1
    pos_device = all_text.find("Device:") + 1
    pos_model = all_text.find("Model:") + 1
    pos_serial = all_text.find("Serial Number:") + 1
    pos_manufacturer = all_text.find("Manufacturer:") + 1
    
    # Apply formatting (simplified for brevity - add all formatting as in dme_complete.py)
    try:
        if pos_dme > 0:
            docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': [
                {'updateTextStyle': {'range': {'startIndex': pos_dme, 'endIndex': pos_dme + 7}, 'textStyle': {'bold': True, 'fontSize': {'magnitude': 18, 'unit': 'PT'}}, 'fields': 'bold,fontSize'}},
                {'updateParagraphStyle': {'range': {'startIndex': pos_dme, 'endIndex': pos_dme + 8}, 'paragraphStyle': {'alignment': 'CENTER'}, 'fields': 'alignment'}}
            ]}).execute()
        
        for pos, length in [(pos_device, 7), (pos_model, 6), (pos_serial, 14), (pos_manufacturer, 13)]:
            if pos > 0:
                docs_service.documents().batchUpdate(documentId=doc_id, body={'requests': [
                    {'updateTextStyle': {'range': {'startIndex': pos, 'endIndex': pos + length}, 'textStyle': {'bold': True, 'underline': True}, 'fields': 'bold,underline'}}
                ]}).execute()
    except: pass
    
    doc_url = f"https://docs.google.com/document/d/{doc_id}/edit"
    return doc_url

# ============================================================================
# BATCH PROCESSING
# ============================================================================

def process_uploads(uploaded_files):
    """Process all uploaded files with batch organization"""
    
    # Extract all images (handle ZIP)
    all_images = []
    for file in uploaded_files:
        if file.name.endswith('.zip'):
            with zipfile.ZipFile(io.BytesIO(file.read())) as z:
                for filename in z.namelist():
                    if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                        all_images.append({
                            'name': filename,
                            'bytes': z.read(filename)
                        })
        else:
            all_images.append({
                'name': file.name,
                'bytes': file.read()
            })
    
    if not all_images:
        st.error("‚ùå No valid images found!")
        return None
    
    st.success(f"‚úÖ Found {len(all_images)} images")
    
    # Create master session folder
    session_timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    master_folder_name = f"DME_Upload_{session_timestamp}"
    
    with st.spinner("Creating master folder..."):
        master_folder_id = create_drive_folder(master_folder_name, BASE_FOLDER_ID)
    
    # Split into operations
    operations = [
        all_images[i:i + BATCH_SIZE] 
        for i in range(0, len(all_images), BATCH_SIZE)
    ]
    
    st.info(f"üìä Processing {len(all_images)} images in {len(operations)} operations (max {BATCH_SIZE} per operation)")
    
    # Process each operation
    all_results = []
    
    # Overall progress
    overall_progress = st.progress(0)
    overall_status = st.empty()
    
    for op_idx, operation_images in enumerate(operations, 1):
        st.subheader(f"Operation {op_idx}/{len(operations)}")
        
        # Create operation folder
        op_folder_name = f"Operation_{op_idx:03d}"
        op_folder_id = create_drive_folder(op_folder_name, master_folder_id)
        
        # Operation progress
        op_progress = st.progress(0)
        op_status = st.empty()
        
        operation_results = []
        
        for img_idx, image in enumerate(operation_images, 1):
            global_idx = (op_idx - 1) * BATCH_SIZE + img_idx
            
            op_status.text(f"Processing: {image['name']} ({img_idx}/{len(operation_images)})")
            
            try:
                # Extract
                data = extract_equipment_data(image['bytes'])
                
                # Create doc
                doc_url = create_equipment_doc(data, op_folder_id)
                
                result = {
                    'operation': op_idx,
                    'image': image['name'],
                    'device': data['device'],
                    'model': data['model'],
                    'serial': data['serial'],
                    'manufacturer': data['manufacturer'],
                    'doc_url': doc_url,
                    'status': 'SUCCESS'
                }
                
            except Exception as e:
                result = {
                    'operation': op_idx,
                    'image': image['name'],
                    'error': str(e),
                    'status': 'FAILED'
                }
            
            operation_results.append(result)
            all_results.append(result)
            
            # Update progress
            op_progress.progress(img_idx / len(operation_images))
            overall_progress.progress(global_idx / len(all_images))
            overall_status.text(f"Overall: {global_idx}/{len(all_images)} images processed")
            
            time.sleep(0.5)  # Rate limiting
        
        # Save operation CSV
        op_df = pd.DataFrame(operation_results)
        op_csv = op_df.to_csv(index=False)
        upload_csv_to_drive(op_csv, f"batch_results.csv", op_folder_id)
        
        st.success(f"‚úÖ Operation {op_idx} complete: {len([r for r in operation_results if r['status'] == 'SUCCESS'])}/{len(operation_results)} successful")
    
    # Save master CSV
    master_df = pd.DataFrame(all_results)
    master_csv = master_df.to_csv(index=False)
    upload_csv_to_drive(master_csv, "master_results.csv", master_folder_id)
    
    # Final summary
    success = len([r for r in all_results if r['status'] == 'SUCCESS'])
    failed = len([r for r in all_results if r['status'] == 'FAILED'])
    
    master_folder_url = f"https://drive.google.com/drive/folders/{master_folder_id}"
    
    return {
        'total': len(all_images),
        'operations': len(operations),
        'success': success,
        'failed': failed,
        'master_folder_url': master_folder_url,
        'results': all_results
    }

# ============================================================================
# MAIN UI
# ============================================================================

def main():
    # Header
    st.markdown("""
    <div class="main-header">
        <h1>üìÑ DME PRO</h1>
        <h3>Equipment Documentation System</h3>
        <p>Upload equipment photos ‚Üí Automatic Google Docs creation</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar info
    with st.sidebar:
        st.header("‚ÑπÔ∏è About")
        st.write("""
        This system automatically:
        - Extracts equipment data from photos
        - Creates professional Google Docs
        - Organizes in Drive folders (50 docs per folder)
        - Exports CSV with all results
        """)
        
        st.header("üìä Stats")
        if 'session_stats' not in st.session_state:
            st.session_state.session_stats = {'total_processed': 0, 'sessions': 0}
        
        st.metric("Total Processed", st.session_state.session_stats['total_processed'])
        st.metric("Sessions", st.session_state.session_stats['sessions'])
        
        st.header("üìä Limits")
        st.write(f"""
        - Max {BATCH_SIZE} documents per operation folder
        - Supported formats: JPG, PNG, ZIP
        - Processing: ~5 seconds per image
        """)
    
    # Initialize session state for upload tracking
    if 'upload_key' not in st.session_state:
        st.session_state.upload_key = 0
    
    if 'last_processed_count' not in st.session_state:
        st.session_state.last_processed_count = 0
    
    # Upload section
    st.header("üì§ Upload Equipment Photos")
    
    # Add clear button at top
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col2:
        if st.button("üîÑ New Upload Session", help="Clear and start fresh upload", use_container_width=True):
            st.session_state.upload_key += 1
            st.session_state.last_processed_count = 0
            if 'last_results' in st.session_state:
                del st.session_state.last_results
            st.rerun()
    
    with col3:
        if 'last_results' in st.session_state:
            if st.button("üìä Show Last Results", help="View previous processing results", use_container_width=True):
                st.session_state.show_previous = True
    
    # File uploader with unique key
    uploaded_files = st.file_uploader(
        "Choose images or ZIP file",
        type=['jpg', 'jpeg', 'png', 'zip'],
        accept_multiple_files=True,
        help="Upload multiple photos or a ZIP file containing equipment photos",
        key=f'file_uploader_{st.session_state.upload_key}'
    )
    
    if uploaded_files:
        # Show upload summary
        total_files = len(uploaded_files)
        
        # Info box
        st.info(f"""
        ‚úÖ **{total_files} file(s) uploaded and ready to process**
        
        Click "Start Processing" to create Google Docs for these files only.
        After processing, use "New Upload Session" to upload different files.
        """)
        
        # Show file list
        with st.expander("üìã View uploaded files", expanded=False):
            for idx, file in enumerate(uploaded_files, 1):
                file_size = file.size / 1024  # KB
                st.write(f"{idx}. {file.name} ({file_size:.1f} KB)")
        
        # Process button
        if st.button("üöÄ Start Processing", type="primary", use_container_width=True):
            # Clear any previous results
            if 'last_results' in st.session_state:
                del st.session_state.last_results
            
            with st.spinner("Processing your uploaded files..."):
                results = process_uploads(uploaded_files)
            
            if results:
                # Update stats
                st.session_state.session_stats['total_processed'] += results['total']
                st.session_state.session_stats['sessions'] += 1
                st.session_state.last_processed_count = results['total']
                
                # Store results
                st.session_state.last_results = results
                st.balloons()
                
                # Show results
                display_results(results)
                
                # Prompt for new session
                st.success("""
                ‚úÖ **Processing Complete!**
                
                To upload and process different files, click "New Upload Session" button above.
                """)
    
    # Show previous results if requested
    elif st.session_state.get('show_previous') and 'last_results' in st.session_state:
        st.info("üìã Showing results from previous processing session")
        display_results(st.session_state.last_results)
        st.session_state.show_previous = False
    
    # No files uploaded
    else:
        st.info("""
        üëÜ **Upload your equipment photos above**
        
        You can:
        - Upload multiple individual photos
        - Upload a ZIP file containing photos
        - Drag and drop files
        
        Supported formats: JPG, JPEG, PNG, ZIP
        """)
        
        # Show previous results if available
        if 'last_results' in st.session_state:
            st.divider()
            st.subheader("üìä Previous Session Results")
            
            results = st.session_state.last_results
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Total Images", results['total'])
            with col2:
                st.metric("Success", results['success'])
            with col3:
                st.metric("Failed", results['failed'])
            with col4:
                st.metric("Operations", results['operations'])
            
            # Link to folder
            st.markdown(f"üìÇ [Open Master Folder]({results['master_folder_url']})")
            
            # Download CSV
            df = pd.DataFrame(results['results'])
            csv = df.to_csv(index=False)
            st.download_button(
                label="üì• Download Previous Results CSV",
                data=csv,
                file_name=f"dme_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                mime="text/csv"
            )

def display_results(results):
    """Display processing results"""
    
    # Summary
    st.markdown(f"""
    <div class="success-box">
        <h2>‚úÖ Processing Complete!</h2>
        <p><strong>Total Images:</strong> {results['total']}</p>
        <p><strong>Operations:</strong> {results['operations']}</p>
        <p><strong>Success:</strong> {results['success']}</p>
        <p><strong>Failed:</strong> {results['failed']}</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Master folder link
    st.markdown(f"### üìÇ [Open Master Folder in Google Drive]({results['master_folder_url']})")
    
    # Results table
    st.header("üìä Detailed Results")
    df = pd.DataFrame(results['results'])
    st.dataframe(df, width='stretch')
    
    # Download CSV
    csv = df.to_csv(index=False)
    st.download_button(
        label="üì• Download Results CSV",
        data=csv,
        file_name=f"dme_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
        mime="text/csv",
        use_container_width=True
    )

if __name__ == "__main__":
    main()